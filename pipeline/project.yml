title: "Healthsea ðŸ¦‘âœ¨"
description: "This project uses NER & TEXTCAT to detect and classify health conditions in supplement reviews."
# Variables can be referenced across the project.yml using ${vars.var_name}
vars:
  version: "0.0.0"

  name: "healthsea"
  config: "config_trf"
  train: "train"
  dev: "dev"

  prodigy:
    database_ner: "ner_condition_benefit_2"
    database_textcat: "textcat_sentiment"

  models:
    model_ner: "training/ner/${vars.config}/model-best"
    model_textcat: "training/textcat/${vars.config}/model-best"

  gpu_id: 0
  eval_split: 0.25

# These are the directories that the project needs. The project CLI will make
# sure that they always exist.
directories: ["assets","data","training", "configs", "scripts"]

# Assets that should be downloaded or available in the directory. We're shipping
# them with the project, so they won't have to be downloaded. But the
# 'project assets' command still lets you verify that the checksums match.
assets:
  - dest: "assets/textcat/annotation.jsonl"
    description: "Textcat annotation data exported from Prodigy"

# Workflows are sequences of commands (see below) executed in order. You can
# run them via "spacy project run [workflow]". If a commands's inputs/outputs
# haven't changed, it won't be re-run.
workflows:
  all:
    - requirements

# Project commands, specified in a style similar to CI config files (e.g. Azure
# pipelines). The name is the command name that lets you trigger the command
# via "spacy project run [command] [path]". The help message is optional and
# shown when executing "spacy project run [optional command] [path] --help".
commands:
  - name: "requirements"
    help: "Install dependencies and requirements"
    script:
      - "pip install -r requirements.txt"
      - "python -m spacy download en_core_web_trf"
      - "python -m spacy download en_core_web_lg"

  - name: "generate_pretrain"
    help: "Generate data for pretraining"
    script:
      - "python scripts/generate_pretrain_data.py data/pretrain/reviews.jsonl"

  - name: "train_pretrain"
    help: "Pretraining"
    script:
      - "python -m spacy pretrain configs/pretrain/config.cfg training/pretrain/ --paths.raw_text data/pretrain/reviews.jsonl --gpu-id ${vars.gpu_id}"

  - name: "generate_ner"
    help: "Generate data for NER annotation"
    script:
      - "python scripts/generate_ner_data.py data/ner/ner_annotation.json 1000"

  - name: "annotate_manual_ner"
    help: "Manually annotate data for NER training"
    script:
      - "python -m prodigy ner.manual ${vars.prodigy.database_ner} blank:en data/ner/ner_annotation.json -l CONDITION,BENEFIT"

  - name: "annotate_correct_ner"
    help: "Correct annotation predicted by NER model"
    script:
      - "python -m prodigy ner.correct ${vars.prodigy.database_ner} ${vars.models.model_ner} data/ner/ner_annotation.json -l CONDITION,BENEFIT"

  - name: "export_ner"
    help: "Export NER datasets from prodigy and convert to .spacy format"
    script:
      - "python -m prodigy data-to-spacy data/ner/ -n ${vars.prodigy.database_ner} -es ${vars.eval_split}"
      - "python -m prodigy db-out ${vars.prodigy.database_ner} assets/ner/"

  - name: "train_ner"
    help: "Train NER"
    script:
      - "python -m spacy train configs/ner/${vars.config}.cfg --output training/ner/${vars.config}/ --paths.train data/ner/${vars.train}.spacy --paths.dev data/ner/${vars.dev}.spacy --paths.init_tok2vec training/pretrain/model15.bin --gpu-id ${vars.gpu_id}"
    deps:
      - "configs/ner/${vars.config}.cfg"
      - "data/ner/${vars.train}.spacy"
      - "data/ner/${vars.dev}.spacy"
    outputs:
      - ${vars.models.model_ner}
      - "training/ner/${vars.config}/model-last"

  - name: "evaluate_ner"
    help: "Evaluate NER"
    script:
      - "python -m spacy evaluate ${vars.models.model_ner} data/ner/${vars.dev}.spacy -c scripts/custom_components.py --gpu-id ${vars.gpu_id}"

  - name: "package_ner"
    help: "Package NER"
    script:
      - "python -m spacy package ${vars.models.model_ner} package/ner/${vars.config}/ -f -n healthsea_ner -c scripts/custom_components.py"

  - name: "generate_textcat"
    help: "Generate data for Textcat annotation"
    script:
      - "python scripts/generate_textcat_data.py training/ner/${vars.config}/model-best data/textcat/textcat_annotation.json ${vars.gpu_id}"

  - name: "annotate_manual_textcat"
    help: "Manually annotate data for Textcat training"
    script:
      - "python -m prodigy textcat.manual ${vars.prodigy.database_textcat} data/textcat/textcat_annotation.json -l POSITIVE,NEGATIVE,NEUTRAL,ANAMNESIS --exclusive"

  - name: "annotate_correct_textcat"
    help: "Correct annotation predicted by Textcat model"
    script:
      - "python -m prodigy textcat.correct ${vars.prodigy.database_textcat} ${vars.models.model_textcat} data/textcat/textcat_annotation.json -l POSITIVE,NEGATIVE,NEUTRAL,ANAMNESIS -c textcat"
  
  - name: "export_textcat"
    help: "Export Textcat datasets from prodigy"
    script:
      - "python -m prodigy db-out ${vars.prodigy.database_textcat} assets/textcat/"
      - "python scripts/parse_textcat_data.py assets/textcat/${vars.prodigy.database_textcat}.jsonl data/textcat/${vars.train}.spacy data/textcat/${vars.dev}.spacy ${vars.eval_split}"

  - name: "train_textcat"
    help: "Train Textcat"
    script:
      - "python -m spacy train configs/textcat/${vars.config}.cfg --output training/textcat/${vars.config}/ -c scripts/custom_components.py --paths.ner_model ${vars.models.model_ner}  --paths.train data/textcat/${vars.train}.spacy --paths.dev data/textcat/${vars.dev}.spacy --paths.init_tok2vec training/pretrain/model15.bin --gpu-id ${vars.gpu_id}"

  - name: "evaluate_textcat"
    help: "Evaluate Textcat"
    script:
      - "python -m spacy evaluate ${vars.models.model_textcat} data/textcat/${vars.dev}.spacy --gpu-id ${vars.gpu_id} -c scripts/custom_components.py"

  - name: "assemble"
    help: "Assemble pipelines to healthsea model"
    script:
      - "python -m spacy assemble configs/healthsea/${vars.config}.cfg training/healthsea/${vars.config}/ -c scripts/custom_components.py --paths.textcat_model ${vars.models.model_textcat}"

  - name: "assemble_tok2vec"
    help: "Build one component pipeline with only tok2vec with pretrained weights"
    script:
      - "python -m spacy assemble configs/pretrain/config.cfg training/healthsea/tok2vec/ --paths.init_tok2vec training/pretrain/model15.bin"

  - name: "analyse"
    help: "Analyse reviews with healthsea pipeline"
    script:
      - "python scripts/analyze_reviews.py training/healthsea/${vars.config}/ data/healthsea/analyzed_reviews.json ${vars.gpu_id} 100"

  - name: "process"
    help: "Process analyzed reviews"
    script:
      - "python scripts/process_reviews.py data/healthsea/analyzed_reviews.json data/healthsea/customer/trustfactor.json data/healthsea/scored_reviews.json"


  - name: "create_product"
    help: "Create product lookup dict"
    script:
      - "python scripts/product/lookup_product.py data/healthsea/products.json"


  - name: "group_customer"
    help: "Group reviews to customers"
    script:
      - "python scripts/user_normalization/group_customers.py data/healthsea/customer/grouped_dataset.json"

  - name: "trustfactor"
    help: "Calculate trustfactor per customer"
    script:
      - "python scripts/user_normalization/calculate_trustfactor.py data/healthsea/customer/grouped_dataset.json data/healthsea/products.json data/healthsea/customer/trustfactor.json"

  - name: "calculate_vectors"
    help: "Calculate vectors of condition and benefits"
    script:
      - "python scripts/vectors/calculate_vectors.py data/healthsea/scored_reviews.json training/healthsea/tok2vec/ data/pretrain/condition_vectors.json data/pretrain/benefit_vectors.json ${vars.gpu_id}"

  - name: "cluster_vectors"
    help: "Cluster entities based on similarity"
    script:
      - "python scripts/vectors/cluster_vectors.py data/healthsea/scored_reviews.json data/pretrain/condition_vectors.json data/pretrain/benefit_vectors.json data/healthsea/scored_clustered_reviews.json 0.95 1000"

  - name: "group_reviews"
    help: "Group review to their products and calculate relevance score"
    script:
      - "python scripts/grouping/group_reviews.py data/healthsea/scored_clustered_reviews.json data/healthsea/products.json data/healthsea/substances_per_product.json data/healthsea/healthsea_products.json data/healthsea/healthsea_substance.json"

  - name: "group_conditions"
    help: "Group conditions and sort by highest relevance_score"
    script:
      - "python scripts/grouping/group_condition.py data/healthsea/healthsea_products.json data/healthsea/healthsea_substance.json data/healthsea/healthsea_condition.json"

  - name: "visualize_healthsea"
    help: "Visualize healthsea in Streamlit"
    script:
      - "streamlit run scripts/presentation/healthsea_streamlit.py "

    