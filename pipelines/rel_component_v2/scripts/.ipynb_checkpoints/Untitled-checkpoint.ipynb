{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "465c89a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import json\n",
    "import typer\n",
    "from spacy.tokens import Span, DocBin, Doc\n",
    "from spacy.vocab import Vocab\n",
    "import random\n",
    "from wasabi import Printer\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "from rel_pipeline import get_tokens, calculate_tensor, create_pairs,dict_to_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d9681935",
   "metadata": {},
   "outputs": [],
   "source": [
    "    vocab = Vocab()\n",
    "    spacy.prefer_gpu()\n",
    "\n",
    "    nlp = spacy.load(\"../../ner_component/training/model-best\")\n",
    "    mask_entities = [\"CONDITION\", \"BENEFIT\"]\n",
    "    relations = [\"RELATED\"]\n",
    "\n",
    "    dep = \"../assets/dependencies.json\"\n",
    "    pos = \"../assets/partofspeech.json\"\n",
    "    \n",
    "    dep_list = None\n",
    "    pos_list = None\n",
    "\n",
    "    with open(dep, \"r\") as f:\n",
    "        dep_list = json.load(f)\n",
    "\n",
    "    with open(pos, \"r\") as f:\n",
    "        pos_list = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "61add41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = []\n",
    "with open(\"../assets/annotations.jsonl\",\"r\", encoding=\"utf8\") as jsonfile:\n",
    "        for line in jsonfile:\n",
    "            lines.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2483d72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = []\n",
    "for line in lines:\n",
    "    example = json.loads(line)\n",
    "    if example[\"answer\"] == \"accept\":\n",
    "        doc = nlp(example[\"text\"])\n",
    "        ents_list = []\n",
    "\n",
    "        for span in example[\"spans\"]:\n",
    "            ents_list.append(\n",
    "                Span(\n",
    "                    doc,\n",
    "                    span[\"token_start\"],\n",
    "                    span[\"token_end\"] + 1,\n",
    "                    span[\"label\"],\n",
    "                )\n",
    "            )\n",
    "\n",
    "        doc.set_ents(ents_list)\n",
    "        tokens = get_tokens(doc)\n",
    "        pairs = calculate_tensor(\n",
    "            create_pairs(tokens),\n",
    "            mask_entities,\n",
    "            relations,\n",
    "            dep_list,\n",
    "            pos_list,\n",
    "        )\n",
    "\n",
    "        for relation in example[\"relations\"]:\n",
    "            key1 = (\n",
    "                relation[\"head_span\"][\"token_start\"],\n",
    "                relation[\"head_span\"][\"token_end\"],\n",
    "                relation[\"child_span\"][\"token_start\"],\n",
    "                relation[\"child_span\"][\"token_end\"],\n",
    "            )\n",
    "            key2 = (\n",
    "                relation[\"child_span\"][\"token_start\"],\n",
    "                relation[\"child_span\"][\"token_end\"],\n",
    "                relation[\"head_span\"][\"token_start\"],\n",
    "                relation[\"head_span\"][\"token_end\"],\n",
    "            )\n",
    "\n",
    "            if key1 in pairs:\n",
    "                pairs[key1][\"relation\"][relation[\"label\"]] = 1.0\n",
    "            elif key2 in pairs:\n",
    "                pairs[key2][\"relation\"][relation[\"label\"]] = 1.0\n",
    "\n",
    "        if not doc.has_extension(\"rel\"):\n",
    "            doc.set_extension(\"rel\", default={})\n",
    "        doc._.rel = pairs\n",
    "\n",
    "        docs.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dcb1d7b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                                                                                                 | 0/351 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|██████▏                                                                                                                                                                 | 13/351 [00:27<11:50,  2.10s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-3f8dfe671e0c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mis_unique\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrent_tensor\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mall_tensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m             \u001b[0mduplicates\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m             \u001b[0mis_unique\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36misin\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32mc:\\users\\edwar\\desktop\\explosion\\envs\\py392\\lib\\site-packages\\numpy\\lib\\arraysetops.py\u001b[0m in \u001b[0;36misin\u001b[1;34m(element, test_elements, assume_unique, invert)\u001b[0m\n\u001b[0;32m    708\u001b[0m     \"\"\"\n\u001b[0;32m    709\u001b[0m     \u001b[0melement\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melement\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 710\u001b[1;33m     return in1d(element, test_elements, assume_unique=assume_unique,\n\u001b[0m\u001b[0;32m    711\u001b[0m                 invert=invert).reshape(element.shape)\n\u001b[0;32m    712\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36min1d\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32mc:\\users\\edwar\\desktop\\explosion\\envs\\py392\\lib\\site-packages\\numpy\\lib\\arraysetops.py\u001b[0m in \u001b[0;36min1d\u001b[1;34m(ar1, ar2, assume_unique, invert)\u001b[0m\n\u001b[0;32m    587\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0massume_unique\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m         \u001b[0mar1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrev_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mar1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 589\u001b[1;33m         \u001b[0mar2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mar2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    590\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    591\u001b[0m     \u001b[0mar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mar1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mar2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36munique\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32mc:\\users\\edwar\\desktop\\explosion\\envs\\py392\\lib\\site-packages\\numpy\\lib\\arraysetops.py\u001b[0m in \u001b[0;36munique\u001b[1;34m(ar, return_index, return_inverse, return_counts, axis)\u001b[0m\n\u001b[0;32m    260\u001b[0m     \u001b[0mar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_unique1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_counts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    263\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_unpack_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\edwar\\desktop\\explosion\\envs\\py392\\lib\\site-packages\\numpy\\lib\\arraysetops.py\u001b[0m in \u001b[0;36m_unique1d\u001b[1;34m(ar, return_index, return_inverse, return_counts)\u001b[0m\n\u001b[0;32m    321\u001b[0m         \u001b[0maux\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mar\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mperm\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 323\u001b[1;33m         \u001b[0mar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    324\u001b[0m         \u001b[0maux\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mar\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m     \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maux\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbool_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "all_tensors = []\n",
    "duplicates = 0\n",
    "conflicts = 0\n",
    "examples = 0\n",
    "\n",
    "print(len(docs))\n",
    "for i in tqdm(range(len(docs))):\n",
    "    doc = docs[i]\n",
    "    relations = doc._.rel\n",
    "    examples += len(relations)\n",
    "    for pair in relations:\n",
    "        current_tensor = relations[pair][\"tensor\"]\n",
    "        current_prediction = dict_to_vector(relations[pair][\"relation\"])\n",
    "        is_unique = True\n",
    "        \n",
    "        if np.isin(current_tensor,all_tensors).all():\n",
    "            duplicates+=1\n",
    "            is_unique = False\n",
    "        \n",
    "        #for tensor in all_tensors:\n",
    "        #    if np.array_equal(current_tensor,tensor[0]):\n",
    "        #        duplicates+=1\n",
    "        #        is_unique = False\n",
    "        #        if np.array_equal(current_prediction,tensor[1]):\n",
    "        #            conflicts+=1\n",
    "                    \n",
    "        if is_unique:\n",
    "            all_tensors.append(current_tensor)\n",
    "        \n",
    "print(len(all_tensors))        \n",
    "print(duplicates,conflicts,examples)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
